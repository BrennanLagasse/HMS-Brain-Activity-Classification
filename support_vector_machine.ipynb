{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.datasets as skdata\n",
    "import sklearn.metrics as skmetrics\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE SURE TO CHANGE THIS TO THE LOCAL PATH TO DATA\n",
    "#TRAIN_PATH = \"../augmented_train/reformatted_train_10000_samples.csv\"\n",
    "TRAIN_PATH = \"train_1998_samples_fft_0_to_10_hz_consensus_1.0_balanced.csv\"\n",
    "data = pd.read_csv(TRAIN_PATH)\n",
    "data_np = data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input = data_np.shape[1] - 1\n",
    "\n",
    "x = data_np[:, 0:num_input]\n",
    "y = data_np[:, num_input]\n",
    "\n",
    "# Shuffle the dataset based on sample indices\n",
    "shuffled_indices = np.random.permutation(x.shape[0])\n",
    "\n",
    "# Choose the first 80% as training set, next 10% as validation and the rest as testing\n",
    "train_split_idx = int(0.80 * x.shape[0])\n",
    "val_split_idx = int(0.90 * x.shape[0])\n",
    "\n",
    "train_indices = shuffled_indices[0:train_split_idx]\n",
    "val_indices = shuffled_indices[train_split_idx:val_split_idx]\n",
    "test_indices = shuffled_indices[val_split_idx:]\n",
    "\n",
    "# Select the examples from x and y to construct our training, validation, testing sets\n",
    "x_train, y_train = x[train_indices, :], y[train_indices]\n",
    "x_val, y_val = x[val_indices, :], y[val_indices]\n",
    "x_test, y_test = x[test_indices, :], y[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernels: linear, tolerances: 0.5\n",
      "Training accuracy: 100.00000%  Validation accuracy: 47.74% Testing accuracy: 52.26%\n",
      "kernels: linear, tolerances: 0.1\n",
      "Training accuracy: 100.00000%  Validation accuracy: 48.24% Testing accuracy: 51.26%\n",
      "kernels: linear, tolerances: 0.01\n",
      "Training accuracy: 100.00000%  Validation accuracy: 48.24% Testing accuracy: 51.26%\n",
      "kernels: linear, tolerances: 0.001\n",
      "Training accuracy: 100.00000%  Validation accuracy: 48.24% Testing accuracy: 51.26%\n",
      "kernels: linear, tolerances: 0.0001\n",
      "Training accuracy: 100.00000%  Validation accuracy: 48.24% Testing accuracy: 51.26%\n",
      "kernels: poly, tolerances: 0.5\n",
      "Training accuracy: 21.49591%  Validation accuracy: 15.58% Testing accuracy: 20.10%\n",
      "kernels: poly, tolerances: 0.1\n",
      "Training accuracy: 21.49591%  Validation accuracy: 15.58% Testing accuracy: 20.10%\n",
      "kernels: poly, tolerances: 0.01\n",
      "Training accuracy: 21.49591%  Validation accuracy: 15.58% Testing accuracy: 20.10%\n",
      "kernels: poly, tolerances: 0.001\n",
      "Training accuracy: 21.49591%  Validation accuracy: 15.58% Testing accuracy: 20.10%\n",
      "kernels: poly, tolerances: 0.0001\n",
      "Training accuracy: 21.49591%  Validation accuracy: 15.58% Testing accuracy: 20.10%\n",
      "kernels: rbf, tolerances: 0.5\n",
      "Training accuracy: 22.69013%  Validation accuracy: 16.58% Testing accuracy: 22.11%\n",
      "kernels: rbf, tolerances: 0.1\n",
      "Training accuracy: 22.81584%  Validation accuracy: 16.58% Testing accuracy: 21.61%\n",
      "kernels: rbf, tolerances: 0.01\n",
      "Training accuracy: 22.75299%  Validation accuracy: 16.58% Testing accuracy: 21.61%\n",
      "kernels: rbf, tolerances: 0.001\n",
      "Training accuracy: 22.75299%  Validation accuracy: 16.58% Testing accuracy: 21.61%\n",
      "kernels: rbf, tolerances: 0.0001\n",
      "Training accuracy: 22.75299%  Validation accuracy: 16.58% Testing accuracy: 21.61%\n",
      "Best model with kernel linear and tolerance 0.5\n",
      "\n",
      " with error: 0.5226130653266332\n"
     ]
    }
   ],
   "source": [
    "model = SVC\n",
    "models= []\n",
    "kernels = ['linear', 'poly', 'rbf']\n",
    "model_scores = []\n",
    "tolerances = [5e-1, 1e-1, 1e-2, 1e-3, 1e-4]\n",
    "\n",
    "#testing out various kernels and conditions for convergence\n",
    "for kernel in kernels:\n",
    "    for tolerance in tolerances:\n",
    "        model = SVC(tol = tolerance, kernel = kernel)\n",
    "        model.fit(x_train, y_train)\n",
    "        models.append(model)\n",
    "\n",
    "        predictions_train = model.predict(x_train)\n",
    "        score_train = skmetrics.accuracy_score(predictions_train, y_train)\n",
    "\n",
    "        predictions_val = model.predict(x_val)\n",
    "        score_val = skmetrics.accuracy_score(predictions_val, y_val)\n",
    "\n",
    "        predictions_test = model.predict(x_test)\n",
    "        score_test = skmetrics.accuracy_score(predictions_test, y_test)\n",
    "\n",
    "        model_scores.append(score_test)\n",
    "        print('kernel: {}, tolerance: {}'.format(kernel, tolerance))\n",
    "        print('Training accuracy: {:0.5f}%  Validation accuracy: {:0.2f}% Testing accuracy: {:0.2f}%'.format(score_train*100, score_val*100, score_test*100))\n",
    "\n",
    "best_model_idx = np.argmax(model_scores)\n",
    "best_model = models[best_model_idx]\n",
    "best_model_prediction = models[best_model_idx].predict(x_test)\n",
    "\n",
    "print('Best model with kernel {} and tolerance {}'.format(kernels[best_model_idx//len(tolerances)], tolerances[best_model_idx%len(tolerances)]))\n",
    "print('\\n with error: {}'.format(model_scores[best_model_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"reformatted_train_10000_samples.csv\"\n",
    "\n",
    "data = pd.read_csv(TRAIN_PATH)\n",
    "\n",
    "data_np = data.to_numpy()\n",
    "\n",
    "print(data_np)\n",
    "print(data_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_np[:, 0:820]\n",
    "y = data_np[:, 820]\n",
    "\n",
    "# Shuffle the dataset based on sample indices\n",
    "shuffled_indices = np.random.permutation(x.shape[0])\n",
    "\n",
    "# Choose the first 80% as training set, next 10% as validation and the rest as testing\n",
    "train_split_idx = int(0.80 * x.shape[0])\n",
    "val_split_idx = int(0.90 * x.shape[0])\n",
    "\n",
    "train_indices = shuffled_indices[0:train_split_idx]\n",
    "val_indices = shuffled_indices[train_split_idx:val_split_idx]\n",
    "test_indices = shuffled_indices[val_split_idx:]\n",
    "\n",
    "# Select the examples from x and y to construct our training, validation, testing sets\n",
    "x_train, y_train = x[train_indices, :], y[train_indices]\n",
    "x_val, y_val = x[val_indices, :], y[val_indices]\n",
    "x_test, y_test = x[test_indices, :], y[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing best model on transformed dataset\n",
    "model = SVC()\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "predictions_train = model.predict(x_train)\n",
    "score_train = skmetrics.accuracy_score(predictions_train, y_train)\n",
    "\n",
    "predictions_val = model.predict(x_val)\n",
    "score_val = skmetrics.accuracy_score(predictions_val, y_val)\n",
    "\n",
    "predictions_test = model.predict(x_test)\n",
    "score_test = skmetrics.accuracy_score(predictions_test, y_test)\n",
    "\n",
    "print('Training accuracy: {:0.2f}%\\nValidation accuracy: {:0.2f}%\\nTest accuracy: {:0.2f}%'.format(score_train*100, score_val*100, score_test*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
